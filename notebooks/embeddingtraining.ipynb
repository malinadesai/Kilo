{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbc2e60d-9697-4c4e-8f7f-b20d54f13ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys, time, glob\n",
    "import json\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbfb03a1-584c-423f-836b-2cc062538d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44c4da54-98b0-47d1-9948-a6419fbabd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extras\n",
    "from IPython.display import clear_output\n",
    "from time import time\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2589cb1e-8aa2-48e9-bb27-5cc52a3ad3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing functions\n",
    "from embedding import SimilarityEmbedding, VICRegLoss, train_one_epoch_se, val_one_epoch_se\n",
    "from data_processing import Paper_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dc80365-5cab-45e1-8f32-583af94509a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "# checking gpu status, ensures tensors are stored on the same device\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebf22ec-7f86-4a26-9dd6-b7ca46f431e5",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7294379d-3358-4a11-8e02-5341125f4c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in tensors\n",
    "\n",
    "data_shifted_paper = torch.load('/nobackup/users/mmdesai/updated_tensors/data_shifted_paper4.pt')\n",
    "data_unshifted_paper = torch.load('/nobackup/users/mmdesai/updated_tensors/data_unshifted_paper4.pt')\n",
    "param_shifted_paper = torch.load('/nobackup/users/mmdesai/updated_tensors/param_shifted_paper4.pt')\n",
    "param_unshifted_paper = torch.load('/nobackup/users/mmdesai/updated_tensors/param_unshifted_paper4.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5600dd2b-b27a-44ef-9c3a-7a9c6f046448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the dataset\n",
    "\n",
    "num_batches_paper_sample = len(data_shifted_paper)\n",
    "dataset_paper = Paper_data(data_shifted_paper, data_unshifted_paper, param_shifted_paper, param_unshifted_paper, num_batches_paper_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27ae451c-9096-431f-a97d-8f8bf23181e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into training, testing, and validation\n",
    "\n",
    "num_batches_paper_sample = len(data_shifted_paper)\n",
    "\n",
    "train_set_size_paper = int(0.8 * num_batches_paper_sample)    \n",
    "val_set_size_paper = int(0.1 * num_batches_paper_sample)     \n",
    "test_set_size_paper = num_batches_paper_sample - train_set_size_paper - val_set_size_paper\n",
    "\n",
    "train_data_paper, val_data_paper, test_data_paper = torch.utils.data.random_split(\n",
    "    dataset_paper, [train_set_size_paper, val_set_size_paper, test_set_size_paper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3851edda-4c58-4ea6-9c83-152f0f6f26c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and shuffle the data\n",
    "\n",
    "train_data_loader_paper = DataLoader(train_data_paper, batch_size=25, shuffle=True)\n",
    "val_data_loader_paper = DataLoader(val_data_paper, batch_size=25, shuffle=True)\n",
    "test_data_loader_paper = DataLoader(test_data_paper, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20507d70-7ec2-4890-b9e3-87fc0b1625a3",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57b901a5-0cfb-41bd-b23d-d8bf38a9e237",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_embedding = SimilarityEmbedding(num_dim=7, num_hidden_layers_f=1, num_hidden_layers_h=1, num_blocks=4, kernel_size=5, num_dim_final=2).to(device)\n",
    "num_dim = 7\n",
    "\n",
    "# optimizes\n",
    "optimizer = optim.Adam(similarity_embedding.parameters(), lr=0.000004)\n",
    "\n",
    "# define the loss\n",
    "vicreg_loss = VICRegLoss()\n",
    "\n",
    "# sets learning rate steps\n",
    "scheduler_1 = optim.lr_scheduler.ConstantLR(optimizer, total_iters=5) #constant lr\n",
    "scheduler_2 = optim.lr_scheduler.OneCycleLR(optimizer, total_steps=20, max_lr=2e-3) #one cycle - increase and then decrease\n",
    "scheduler_3 = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "scheduler = optim.lr_scheduler.SequentialLR(optimizer, schedulers=[scheduler_1, scheduler_2, scheduler_3], milestones=[5, 15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84aa32f3-2c70-4567-915e-7eef5997947e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_norm.weight\n",
      "363\n",
      "layer_norm.bias\n",
      "363\n",
      "layers_f.conv1.weight\n",
      "1344\n",
      "layers_f.bn1.weight\n",
      "64\n",
      "layers_f.bn1.bias\n",
      "64\n",
      "layers_f.residual_layers.0.0.conv1.weight\n",
      "20480\n",
      "layers_f.residual_layers.0.0.bn1.weight\n",
      "64\n",
      "layers_f.residual_layers.0.0.bn1.bias\n",
      "64\n",
      "layers_f.residual_layers.0.0.conv2.weight\n",
      "20480\n",
      "layers_f.residual_layers.0.0.bn2.weight\n",
      "64\n",
      "layers_f.residual_layers.0.0.bn2.bias\n",
      "64\n",
      "layers_f.residual_layers.0.1.conv1.weight\n",
      "20480\n",
      "layers_f.residual_layers.0.1.bn1.weight\n",
      "64\n",
      "layers_f.residual_layers.0.1.bn1.bias\n",
      "64\n",
      "layers_f.residual_layers.0.1.conv2.weight\n",
      "20480\n",
      "layers_f.residual_layers.0.1.bn2.weight\n",
      "64\n",
      "layers_f.residual_layers.0.1.bn2.bias\n",
      "64\n",
      "layers_f.residual_layers.1.0.conv1.weight\n",
      "40960\n",
      "layers_f.residual_layers.1.0.bn1.weight\n",
      "128\n",
      "layers_f.residual_layers.1.0.bn1.bias\n",
      "128\n",
      "layers_f.residual_layers.1.0.conv2.weight\n",
      "81920\n",
      "layers_f.residual_layers.1.0.bn2.weight\n",
      "128\n",
      "layers_f.residual_layers.1.0.bn2.bias\n",
      "128\n",
      "layers_f.residual_layers.1.0.downsample.0.weight\n",
      "8192\n",
      "layers_f.residual_layers.1.0.downsample.1.weight\n",
      "128\n",
      "layers_f.residual_layers.1.0.downsample.1.bias\n",
      "128\n",
      "layers_f.residual_layers.1.1.conv1.weight\n",
      "81920\n",
      "layers_f.residual_layers.1.1.bn1.weight\n",
      "128\n",
      "layers_f.residual_layers.1.1.bn1.bias\n",
      "128\n",
      "layers_f.residual_layers.1.1.conv2.weight\n",
      "81920\n",
      "layers_f.residual_layers.1.1.bn2.weight\n",
      "128\n",
      "layers_f.residual_layers.1.1.bn2.bias\n",
      "128\n",
      "layers_f.fc.weight\n",
      "12800\n",
      "layers_f.fc.bias\n",
      "100\n",
      "contraction_layer.weight\n",
      "700\n",
      "contraction_layer.bias\n",
      "7\n",
      "expander_layer.weight\n",
      "140\n",
      "expander_layer.bias\n",
      "20\n",
      "layers_h.0.weight\n",
      "400\n",
      "layers_h.0.bias\n",
      "20\n",
      "final_layer.weight\n",
      "40\n",
      "final_layer.bias\n",
      "2\n",
      "395051\n"
     ]
    }
   ],
   "source": [
    "# print neural network parameters that require gradients and sum parameters\n",
    "\n",
    "sum_param=0\n",
    "for name, param in similarity_embedding.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)\n",
    "        print(param.numel())\n",
    "        sum_param+=param.numel()\n",
    "print(sum_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86ae971d-9fe9-409c-9e7b-afb36a5c7a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to tensorboard\n",
    "\n",
    "writer = SummaryWriter()\n",
    "epoch_number = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8044570-cdd0-49e9-a2d9-0ff1406b5a7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      " Avg. train loss/batch after 10 batches = 0.9884\n",
      "Last 0.00; 0.00; 0.99\n",
      " Avg. train loss/batch after 20 batches = 0.9851\n",
      "Last 0.00; 0.00; 0.98\n",
      " Avg. train loss/batch after 30 batches = 0.9815\n",
      "Last 0.00; 0.00; 0.98\n",
      " Avg. train loss/batch after 40 batches = 0.9770\n",
      "Last 0.00; 0.00; 0.97\n",
      " Avg. train loss/batch after 50 batches = 0.9715\n",
      "Last 0.00; 0.00; 0.96\n",
      " Avg. train loss/batch after 60 batches = 0.9646\n",
      "Last 0.00; 0.00; 0.95\n",
      " Avg. train loss/batch after 70 batches = 0.9571\n",
      "Last 0.00; 0.00; 0.95\n",
      " Avg. train loss/batch after 80 batches = 0.9498\n",
      "Last 0.01; 0.00; 0.94\n",
      " Avg. train loss/batch after 90 batches = 0.9393\n",
      "Last 0.01; 0.00; 0.92\n",
      " Avg. train loss/batch after 100 batches = 0.9277\n",
      "Last 0.01; 0.00; 0.92\n",
      " Avg. train loss/batch after 110 batches = 0.9162\n",
      "Last 0.02; 0.00; 0.89\n",
      " Avg. train loss/batch after 120 batches = 0.9086\n",
      "Last 0.02; 0.00; 0.88\n",
      " Avg. train loss/batch after 130 batches = 0.8922\n",
      "Last 0.02; 0.00; 0.86\n",
      " Avg. train loss/batch after 140 batches = 0.8838\n",
      "Last 0.03; 0.00; 0.84\n",
      "Train/Val Sim Loss after epoch: 0.8838/0.8804\n",
      "EPOCH 2:\n",
      " Avg. train loss/batch after 10 batches = 0.8675\n",
      "Last 0.03; 0.00; 0.84\n",
      " Avg. train loss/batch after 20 batches = 0.8522\n",
      "Last 0.04; 0.00; 0.81\n",
      " Avg. train loss/batch after 30 batches = 0.8493\n",
      "Last 0.04; 0.00; 0.79\n",
      " Avg. train loss/batch after 40 batches = 0.8269\n",
      "Last 0.04; 0.00; 0.75\n",
      " Avg. train loss/batch after 50 batches = 0.8216\n",
      "Last 0.07; 0.00; 0.75\n",
      " Avg. train loss/batch after 60 batches = 0.8116\n",
      "Last 0.07; 0.00; 0.74\n",
      " Avg. train loss/batch after 70 batches = 0.7916\n",
      "Last 0.06; 0.00; 0.70\n",
      " Avg. train loss/batch after 80 batches = 0.7939\n",
      "Last 0.09; 0.00; 0.70\n",
      " Avg. train loss/batch after 90 batches = 0.7872\n",
      "Last 0.09; 0.00; 0.69\n",
      " Avg. train loss/batch after 100 batches = 0.7638\n",
      "Last 0.08; 0.00; 0.65\n",
      " Avg. train loss/batch after 110 batches = 0.7611\n",
      "Last 0.11; 0.00; 0.65\n",
      " Avg. train loss/batch after 120 batches = 0.7381\n",
      "Last 0.08; 0.00; 0.64\n",
      " Avg. train loss/batch after 130 batches = 0.7437\n",
      "Last 0.13; 0.00; 0.63\n",
      " Avg. train loss/batch after 140 batches = 0.7202\n",
      "Last 0.09; 0.00; 0.60\n",
      "Train/Val Sim Loss after epoch: 0.7202/0.6529\n",
      "EPOCH 3:\n",
      " Avg. train loss/batch after 10 batches = 0.6934\n",
      "Last 0.06; 0.00; 0.55\n",
      " Avg. train loss/batch after 20 batches = 0.6772\n",
      "Last 0.06; 0.00; 0.56\n",
      " Avg. train loss/batch after 30 batches = 0.6579\n",
      "Last 0.07; 0.00; 0.55\n",
      " Avg. train loss/batch after 40 batches = 0.6444\n",
      "Last 0.08; 0.00; 0.54\n",
      " Avg. train loss/batch after 50 batches = 0.6257\n",
      "Last 0.08; 0.00; 0.50\n",
      " Avg. train loss/batch after 60 batches = 0.6210\n",
      "Last 0.10; 0.00; 0.49\n",
      " Avg. train loss/batch after 70 batches = 0.5915\n",
      "Last 0.10; 0.00; 0.50\n",
      " Avg. train loss/batch after 80 batches = 0.5527\n",
      "Last 0.05; 0.00; 0.47\n",
      " Avg. train loss/batch after 90 batches = 0.5330\n",
      "Last 0.10; 0.00; 0.48\n",
      " Avg. train loss/batch after 100 batches = 0.5036\n",
      "Last 0.09; 0.00; 0.43\n",
      " Avg. train loss/batch after 110 batches = 0.5021\n",
      "Last 0.10; 0.00; 0.37\n",
      " Avg. train loss/batch after 120 batches = 0.4654\n",
      "Last 0.12; 0.00; 0.40\n",
      " Avg. train loss/batch after 130 batches = 0.4536\n",
      "Last 0.12; 0.00; 0.37\n",
      " Avg. train loss/batch after 140 batches = 0.4474\n",
      "Last 0.10; 0.00; 0.34\n",
      "Train/Val Sim Loss after epoch: 0.4474/0.5198\n",
      "EPOCH 4:\n",
      " Avg. train loss/batch after 10 batches = 0.3924\n",
      "Last 0.07; 0.00; 0.29\n",
      " Avg. train loss/batch after 20 batches = 0.4102\n",
      "Last 0.16; 0.00; 0.32\n",
      " Avg. train loss/batch after 30 batches = 0.3975\n",
      "Last 0.14; 0.00; 0.23\n",
      " Avg. train loss/batch after 40 batches = 0.3134\n",
      "Last 0.07; 0.00; 0.23\n",
      " Avg. train loss/batch after 50 batches = 0.3215\n",
      "Last 0.11; 0.00; 0.27\n",
      " Avg. train loss/batch after 60 batches = 0.3163\n",
      "Last 0.07; 0.00; 0.19\n",
      " Avg. train loss/batch after 70 batches = 0.3091\n",
      "Last 0.13; 0.00; 0.20\n",
      " Avg. train loss/batch after 80 batches = 0.2783\n",
      "Last 0.11; 0.00; 0.19\n",
      " Avg. train loss/batch after 90 batches = 0.2620\n",
      "Last 0.11; 0.00; 0.16\n",
      " Avg. train loss/batch after 100 batches = 0.2499\n",
      "Last 0.07; 0.00; 0.15\n",
      " Avg. train loss/batch after 110 batches = 0.2364\n",
      "Last 0.12; 0.00; 0.19\n",
      " Avg. train loss/batch after 120 batches = 0.2038\n",
      "Last 0.08; 0.00; 0.12\n",
      " Avg. train loss/batch after 130 batches = 0.2013\n",
      "Last 0.05; 0.00; 0.18\n",
      " Avg. train loss/batch after 140 batches = 0.2146\n",
      "Last 0.11; 0.00; 0.17\n",
      "Train/Val Sim Loss after epoch: 0.2146/0.1420\n",
      "EPOCH 5:\n",
      " Avg. train loss/batch after 10 batches = 0.1868\n",
      "Last 0.07; 0.00; 0.10\n",
      " Avg. train loss/batch after 20 batches = 0.1592\n",
      "Last 0.07; 0.00; 0.09\n",
      " Avg. train loss/batch after 30 batches = 0.1563\n",
      "Last 0.03; 0.00; 0.08\n",
      " Avg. train loss/batch after 40 batches = 0.1639\n",
      "Last 0.07; 0.00; 0.08\n",
      " Avg. train loss/batch after 50 batches = 0.1127\n",
      "Last 0.05; 0.00; 0.07\n",
      " Avg. train loss/batch after 60 batches = 0.1511\n",
      "Last 0.08; 0.00; 0.15\n",
      " Avg. train loss/batch after 70 batches = 0.1282\n",
      "Last 0.06; 0.00; 0.07\n",
      " Avg. train loss/batch after 80 batches = 0.1216\n",
      "Last 0.05; 0.00; 0.04\n",
      " Avg. train loss/batch after 90 batches = 0.1250\n",
      "Last 0.08; 0.00; 0.05\n",
      " Avg. train loss/batch after 100 batches = 0.1067\n",
      "Last 0.05; 0.00; 0.03\n",
      " Avg. train loss/batch after 110 batches = 0.1220\n",
      "Last 0.10; 0.00; 0.10\n",
      " Avg. train loss/batch after 120 batches = 0.0964\n",
      "Last 0.06; 0.00; 0.03\n",
      " Avg. train loss/batch after 130 batches = 0.1168\n",
      "Last 0.06; 0.00; 0.01\n",
      " Avg. train loss/batch after 140 batches = 0.0978\n",
      "Last 0.07; 0.00; 0.02\n",
      "Train/Val Sim Loss after epoch: 0.0978/0.1668\n",
      "EPOCH 6:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmdesai/.conda/envs/my_torch/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Avg. train loss/batch after 10 batches = 0.0788\n",
      "Last 0.06; 0.00; 0.00\n",
      " Avg. train loss/batch after 20 batches = 0.0954\n",
      "Last 0.03; 0.00; 0.00\n",
      " Avg. train loss/batch after 30 batches = 0.0683\n",
      "Last 0.05; 0.00; 0.00\n",
      " Avg. train loss/batch after 40 batches = 0.0926\n",
      "Last 0.05; 0.00; 0.00\n",
      " Avg. train loss/batch after 50 batches = 0.0828\n",
      "Last 0.07; 0.00; 0.00\n",
      " Avg. train loss/batch after 60 batches = 0.0903\n",
      "Last 0.11; 0.00; 0.00\n",
      " Avg. train loss/batch after 70 batches = 0.0733\n",
      "Last 0.06; 0.00; 0.00\n",
      " Avg. train loss/batch after 80 batches = 0.0875\n",
      "Last 0.08; 0.00; 0.00\n",
      " Avg. train loss/batch after 90 batches = 0.0608\n",
      "Last 0.05; 0.00; 0.00\n",
      " Avg. train loss/batch after 100 batches = 0.0575\n",
      "Last 0.06; 0.00; 0.00\n",
      " Avg. train loss/batch after 110 batches = 0.0545\n",
      "Last 0.05; 0.00; 0.00\n",
      " Avg. train loss/batch after 120 batches = 0.0501\n",
      "Last 0.04; 0.00; 0.00\n",
      " Avg. train loss/batch after 130 batches = 0.0514\n",
      "Last 0.04; 0.00; 0.00\n",
      " Avg. train loss/batch after 140 batches = 0.0381\n",
      "Last 0.05; 0.00; 0.00\n",
      "Train/Val Sim Loss after epoch: 0.0381/0.0243\n",
      "EPOCH 7:\n",
      " Avg. train loss/batch after 10 batches = 0.0655\n",
      "Last 0.06; 0.00; 0.00\n",
      " Avg. train loss/batch after 20 batches = 0.0793\n",
      "Last 0.09; 0.00; 0.00\n",
      " Avg. train loss/batch after 30 batches = 0.1148\n",
      "Last 0.07; 0.00; 0.00\n",
      " Avg. train loss/batch after 40 batches = 0.1137\n",
      "Last 0.04; 0.00; 0.00\n",
      " Avg. train loss/batch after 50 batches = 0.0869\n",
      "Last 0.04; 0.00; 0.00\n",
      " Avg. train loss/batch after 60 batches = 0.0494\n",
      "Last 0.05; 0.00; 0.00\n",
      " Avg. train loss/batch after 70 batches = 0.0482\n",
      "Last 0.03; 0.00; 0.00\n",
      " Avg. train loss/batch after 80 batches = 0.0651\n",
      "Last 0.06; 0.00; 0.00\n",
      " Avg. train loss/batch after 90 batches = 0.0434\n",
      "Last 0.04; 0.00; 0.00\n",
      " Avg. train loss/batch after 100 batches = 0.0505\n",
      "Last 0.05; 0.00; 0.00\n",
      " Avg. train loss/batch after 110 batches = 0.0481\n",
      "Last 0.05; 0.00; 0.00\n",
      " Avg. train loss/batch after 120 batches = 0.0520\n",
      "Last 0.04; 0.00; 0.00\n",
      " Avg. train loss/batch after 130 batches = 0.0510\n",
      "Last 0.05; 0.00; 0.07\n",
      " Avg. train loss/batch after 140 batches = 0.0417\n",
      "Last 0.05; 0.00; 0.07\n",
      "Train/Val Sim Loss after epoch: 0.0417/0.0372\n",
      "EPOCH 8:\n",
      " Avg. train loss/batch after 10 batches = 0.0415\n",
      "Last 0.04; 0.00; 0.00\n",
      " Avg. train loss/batch after 20 batches = 0.0760\n",
      "Last 0.05; 0.00; 0.00\n",
      " Avg. train loss/batch after 30 batches = 0.0654\n",
      "Last 0.06; 0.00; 0.01\n",
      " Avg. train loss/batch after 40 batches = 0.0622\n",
      "Last 0.05; 0.00; 0.00\n",
      " Avg. train loss/batch after 50 batches = 0.0748\n",
      "Last 0.07; 0.00; 0.00\n",
      " Avg. train loss/batch after 60 batches = 0.0724\n",
      "Last 0.03; 0.00; 0.00\n",
      " Avg. train loss/batch after 70 batches = 0.1001\n",
      "Last 0.09; 0.00; 0.00\n",
      " Avg. train loss/batch after 80 batches = 0.0827\n",
      "Last 0.04; 0.01; 0.15\n",
      " Avg. train loss/batch after 90 batches = 0.0697\n",
      "Last 0.04; 0.00; 0.00\n",
      " Avg. train loss/batch after 100 batches = 0.0396\n",
      "Last 0.03; 0.00; 0.00\n",
      " Avg. train loss/batch after 110 batches = 0.0413\n",
      "Last 0.05; 0.00; 0.00\n",
      " Avg. train loss/batch after 120 batches = 0.0382\n",
      "Last 0.04; 0.00; 0.00\n",
      " Avg. train loss/batch after 130 batches = 0.0298\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 140 batches = 0.0313\n",
      "Last 0.02; 0.00; 0.02\n",
      "Train/Val Sim Loss after epoch: 0.0313/0.0207\n",
      "EPOCH 9:\n",
      " Avg. train loss/batch after 10 batches = 0.0364\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 20 batches = 0.0667\n",
      "Last 0.07; 0.00; 0.00\n",
      " Avg. train loss/batch after 30 batches = 0.0848\n",
      "Last 0.04; 0.00; 0.00\n",
      " Avg. train loss/batch after 40 batches = 0.0784\n",
      "Last 0.05; 0.00; 0.00\n",
      " Avg. train loss/batch after 50 batches = 0.0890\n",
      "Last 0.10; 0.01; 0.26\n",
      " Avg. train loss/batch after 60 batches = 0.1753\n",
      "Last 0.19; 0.00; 0.01\n",
      " Avg. train loss/batch after 70 batches = 0.0946\n",
      "Last 0.06; 0.00; 0.00\n",
      " Avg. train loss/batch after 80 batches = 0.0471\n",
      "Last 0.05; 0.00; 0.01\n",
      " Avg. train loss/batch after 90 batches = 0.0344\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 100 batches = 0.0590\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 110 batches = 0.0611\n",
      "Last 0.06; 0.00; 0.00\n",
      " Avg. train loss/batch after 120 batches = 0.0890\n",
      "Last 0.04; 0.00; 0.00\n",
      " Avg. train loss/batch after 130 batches = 0.0808\n",
      "Last 0.05; 0.00; 0.00\n",
      " Avg. train loss/batch after 140 batches = 0.0483\n",
      "Last 0.04; 0.00; 0.00\n",
      "Train/Val Sim Loss after epoch: 0.0483/0.0463\n",
      "EPOCH 10:\n",
      " Avg. train loss/batch after 10 batches = 0.0510\n",
      "Last 0.08; 0.00; 0.00\n",
      " Avg. train loss/batch after 20 batches = 0.0388\n",
      "Last 0.03; 0.00; 0.01\n",
      " Avg. train loss/batch after 30 batches = 0.0335\n",
      "Last 0.03; 0.00; 0.00\n",
      " Avg. train loss/batch after 40 batches = 0.0303\n",
      "Last 0.04; 0.00; 0.00\n",
      " Avg. train loss/batch after 50 batches = 0.0251\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 60 batches = 0.0249\n",
      "Last 0.03; 0.00; 0.00\n",
      " Avg. train loss/batch after 70 batches = 0.0365\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 80 batches = 0.0301\n",
      "Last 0.03; 0.00; 0.00\n",
      " Avg. train loss/batch after 90 batches = 0.0296\n",
      "Last 0.03; 0.00; 0.00\n",
      " Avg. train loss/batch after 100 batches = 0.0296\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 110 batches = 0.0343\n",
      "Last 0.04; 0.00; 0.00\n",
      " Avg. train loss/batch after 120 batches = 0.0287\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 130 batches = 0.0363\n",
      "Last 0.06; 0.00; 0.00\n",
      " Avg. train loss/batch after 140 batches = 0.0397\n",
      "Last 0.03; 0.00; 0.00\n",
      "Train/Val Sim Loss after epoch: 0.0397/0.0478\n",
      "EPOCH 11:\n",
      " Avg. train loss/batch after 10 batches = 0.0316\n",
      "Last 0.01; 0.01; 0.05\n",
      " Avg. train loss/batch after 20 batches = 0.0561\n",
      "Last 0.06; 0.00; 0.00\n",
      " Avg. train loss/batch after 30 batches = 0.0557\n",
      "Last 0.05; 0.00; 0.00\n",
      " Avg. train loss/batch after 40 batches = 0.0401\n",
      "Last 0.03; 0.00; 0.00\n",
      " Avg. train loss/batch after 50 batches = 0.0334\n",
      "Last 0.03; 0.00; 0.00\n",
      " Avg. train loss/batch after 60 batches = 0.0313\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 70 batches = 0.0281\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 80 batches = 0.0329\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 90 batches = 0.0541\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 100 batches = 0.0288\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 110 batches = 0.0253\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 120 batches = 0.1045\n",
      "Last 0.27; 0.00; 0.00\n",
      " Avg. train loss/batch after 130 batches = 0.2433\n",
      "Last 0.15; 0.00; 0.00\n",
      " Avg. train loss/batch after 140 batches = 0.0724\n",
      "Last 0.03; 0.01; 0.00\n",
      "Train/Val Sim Loss after epoch: 0.0724/0.1208\n",
      "EPOCH 12:\n",
      " Avg. train loss/batch after 10 batches = 0.0650\n",
      "Last 0.03; 0.00; 0.00\n",
      " Avg. train loss/batch after 20 batches = 0.0600\n",
      "Last 0.04; 0.00; 0.00\n",
      " Avg. train loss/batch after 30 batches = 0.0384\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 40 batches = 0.0308\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 50 batches = 0.0685\n",
      "Last 0.05; 0.00; 0.00\n",
      " Avg. train loss/batch after 60 batches = 0.0641\n",
      "Last 0.02; 0.01; 0.02\n",
      " Avg. train loss/batch after 70 batches = 0.0814\n",
      "Last 0.11; 0.00; 0.00\n",
      " Avg. train loss/batch after 80 batches = 0.0663\n",
      "Last 0.05; 0.00; 0.00\n",
      " Avg. train loss/batch after 90 batches = 0.0391\n",
      "Last 0.03; 0.00; 0.00\n",
      " Avg. train loss/batch after 100 batches = 0.0299\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 110 batches = 0.0258\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 120 batches = 0.0257\n",
      "Last 0.03; 0.00; 0.00\n",
      " Avg. train loss/batch after 130 batches = 0.0293\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 140 batches = 0.0270\n",
      "Last 0.03; 0.00; 0.00\n",
      "Train/Val Sim Loss after epoch: 0.0270/0.0314\n",
      "EPOCH 13:\n",
      " Avg. train loss/batch after 10 batches = 0.0321\n",
      "Last 0.02; 0.00; 0.01\n",
      " Avg. train loss/batch after 20 batches = 0.0227\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 30 batches = 0.0333\n",
      "Last 0.05; 0.00; 0.00\n",
      " Avg. train loss/batch after 40 batches = 0.0291\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 50 batches = 0.0289\n",
      "Last 0.05; 0.00; 0.00\n",
      " Avg. train loss/batch after 60 batches = 0.0263\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 70 batches = 0.1163\n",
      "Last 0.04; 0.02; 0.20\n",
      " Avg. train loss/batch after 80 batches = 0.0777\n",
      "Last 0.04; 0.00; 0.00\n",
      " Avg. train loss/batch after 90 batches = 0.0346\n",
      "Last 0.03; 0.00; 0.00\n",
      " Avg. train loss/batch after 100 batches = 0.0222\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 110 batches = 0.0640\n",
      "Last 0.03; 0.00; 0.00\n",
      " Avg. train loss/batch after 120 batches = 0.0385\n",
      "Last 0.03; 0.00; 0.00\n",
      " Avg. train loss/batch after 130 batches = 0.0419\n",
      "Last 0.04; 0.00; 0.00\n",
      " Avg. train loss/batch after 140 batches = 0.0311\n",
      "Last 0.02; 0.00; 0.13\n",
      "Train/Val Sim Loss after epoch: 0.0311/0.1905\n",
      "EPOCH 14:\n",
      " Avg. train loss/batch after 10 batches = 0.0276\n",
      "Last 0.03; 0.00; 0.00\n",
      " Avg. train loss/batch after 20 batches = 0.0218\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 30 batches = 0.0229\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 40 batches = 0.0226\n",
      "Last 0.03; 0.00; 0.00\n",
      " Avg. train loss/batch after 50 batches = 0.0175\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 60 batches = 0.0247\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 70 batches = 0.0258\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 80 batches = 0.0271\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 90 batches = 0.0364\n",
      "Last 0.04; 0.00; 0.00\n",
      " Avg. train loss/batch after 100 batches = 0.0358\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 110 batches = 0.0613\n",
      "Last 0.08; 0.00; 0.00\n",
      " Avg. train loss/batch after 120 batches = 0.0388\n",
      "Last 0.03; 0.00; 0.00\n",
      " Avg. train loss/batch after 130 batches = 0.0175\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 140 batches = 0.0183\n",
      "Last 0.01; 0.00; 0.00\n",
      "Train/Val Sim Loss after epoch: 0.0183/0.0161\n",
      "EPOCH 15:\n",
      " Avg. train loss/batch after 10 batches = 0.0548\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 20 batches = 0.0207\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 30 batches = 0.0182\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 40 batches = 0.0153\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 50 batches = 0.0179\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 60 batches = 0.0247\n",
      "Last 0.03; 0.00; 0.00\n",
      " Avg. train loss/batch after 70 batches = 0.0216\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 80 batches = 0.0181\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 90 batches = 0.0184\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 100 batches = 0.0212\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 110 batches = 0.0233\n",
      "Last 0.03; 0.00; 0.00\n",
      " Avg. train loss/batch after 120 batches = 0.0244\n",
      "Last 0.03; 0.00; 0.00\n",
      " Avg. train loss/batch after 130 batches = 0.0215\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 140 batches = 0.0182\n",
      "Last 0.01; 0.00; 0.00\n",
      "Train/Val Sim Loss after epoch: 0.0182/0.0228\n",
      "EPOCH 16:\n",
      " Avg. train loss/batch after 10 batches = 0.0145\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 20 batches = 0.0250\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 30 batches = 0.0159\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 40 batches = 0.0177\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 50 batches = 0.0147\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 60 batches = 0.0250\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 70 batches = 0.0177\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 80 batches = 0.0155\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 90 batches = 0.0163\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 100 batches = 0.0164\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 110 batches = 0.0231\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 120 batches = 0.0157\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 130 batches = 0.0159\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 140 batches = 0.0174\n",
      "Last 0.01; 0.01; 0.00\n",
      "Train/Val Sim Loss after epoch: 0.0174/0.0158\n",
      "EPOCH 17:\n",
      " Avg. train loss/batch after 10 batches = 0.0178\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 20 batches = 0.0160\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 30 batches = 0.0167\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 40 batches = 0.0164\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 50 batches = 0.0152\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 60 batches = 0.0152\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 70 batches = 0.0182\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 80 batches = 0.0160\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 90 batches = 0.0179\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 100 batches = 0.0139\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 110 batches = 0.0174\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 120 batches = 0.0150\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 130 batches = 0.0166\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 140 batches = 0.0154\n",
      "Last 0.02; 0.00; 0.00\n",
      "Train/Val Sim Loss after epoch: 0.0154/0.0211\n",
      "EPOCH 18:\n",
      " Avg. train loss/batch after 10 batches = 0.0187\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 20 batches = 0.0157\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 30 batches = 0.0168\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 40 batches = 0.0170\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 50 batches = 0.0180\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 60 batches = 0.0158\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 70 batches = 0.0176\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 80 batches = 0.0168\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 90 batches = 0.0138\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 100 batches = 0.0163\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 110 batches = 0.0369\n",
      "Last 0.01; 0.01; 0.22\n",
      " Avg. train loss/batch after 120 batches = 0.0142\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 130 batches = 0.0153\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 140 batches = 0.0153\n",
      "Last 0.01; 0.00; 0.00\n",
      "Train/Val Sim Loss after epoch: 0.0153/0.0164\n",
      "EPOCH 19:\n",
      " Avg. train loss/batch after 10 batches = 0.0414\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 20 batches = 0.0199\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 30 batches = 0.0145\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 40 batches = 0.0163\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 50 batches = 0.0146\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 60 batches = 0.0170\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 70 batches = 0.0155\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 80 batches = 0.0173\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 90 batches = 0.0146\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 100 batches = 0.0229\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 110 batches = 0.0151\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 120 batches = 0.0144\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 130 batches = 0.0155\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 140 batches = 0.0141\n",
      "Last 0.01; 0.00; 0.00\n",
      "Train/Val Sim Loss after epoch: 0.0141/0.0163\n",
      "EPOCH 20:\n",
      " Avg. train loss/batch after 10 batches = 0.0146\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 20 batches = 0.0140\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 30 batches = 0.0146\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 40 batches = 0.0147\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 50 batches = 0.0149\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 60 batches = 0.0142\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 70 batches = 0.0221\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 80 batches = 0.0159\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 90 batches = 0.0152\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 100 batches = 0.0172\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 110 batches = 0.0163\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 120 batches = 0.0150\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 130 batches = 0.0146\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 140 batches = 0.0194\n",
      "Last 0.01; 0.00; 0.00\n",
      "Train/Val Sim Loss after epoch: 0.0194/0.0131\n",
      "EPOCH 21:\n",
      " Avg. train loss/batch after 10 batches = 0.0212\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 20 batches = 0.0148\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 30 batches = 0.0136\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 40 batches = 0.0174\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 50 batches = 0.0155\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 60 batches = 0.0168\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 70 batches = 0.0155\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 80 batches = 0.0274\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 90 batches = 0.0160\n",
      "Last 0.01; 0.00; 0.02\n",
      " Avg. train loss/batch after 100 batches = 0.0142\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 110 batches = 0.0170\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 120 batches = 0.0141\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 130 batches = 0.0161\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 140 batches = 0.0131\n",
      "Last 0.01; 0.00; 0.00\n",
      "Train/Val Sim Loss after epoch: 0.0131/0.0201\n",
      "EPOCH 22:\n",
      " Avg. train loss/batch after 10 batches = 0.0158\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 20 batches = 0.0180\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 30 batches = 0.0136\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 40 batches = 0.0174\n",
      "Last 0.01; 0.00; 0.01\n",
      " Avg. train loss/batch after 50 batches = 0.0149\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 60 batches = 0.0343\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 70 batches = 0.0159\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 80 batches = 0.0146\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 90 batches = 0.0166\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 100 batches = 0.0160\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 110 batches = 0.0155\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 120 batches = 0.0172\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 130 batches = 0.0218\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 140 batches = 0.0135\n",
      "Last 0.01; 0.01; 0.00\n",
      "Train/Val Sim Loss after epoch: 0.0135/0.0172\n",
      "EPOCH 23:\n",
      " Avg. train loss/batch after 10 batches = 0.0169\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 20 batches = 0.0165\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 30 batches = 0.0190\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 40 batches = 0.0150\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 50 batches = 0.0202\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 60 batches = 0.0175\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 70 batches = 0.0167\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 80 batches = 0.0158\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 90 batches = 0.0159\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 100 batches = 0.0172\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 110 batches = 0.0158\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 120 batches = 0.0152\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 130 batches = 0.0147\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 140 batches = 0.0157\n",
      "Last 0.01; 0.00; 0.00\n",
      "Train/Val Sim Loss after epoch: 0.0157/0.0212\n",
      "EPOCH 24:\n",
      " Avg. train loss/batch after 10 batches = 0.0138\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 20 batches = 0.0169\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 30 batches = 0.0221\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 40 batches = 0.0140\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 50 batches = 0.0226\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 60 batches = 0.0167\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 70 batches = 0.0199\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 80 batches = 0.0183\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 90 batches = 0.0164\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 100 batches = 0.0168\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 110 batches = 0.0167\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 120 batches = 0.0157\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 130 batches = 0.0174\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 140 batches = 0.0167\n",
      "Last 0.02; 0.00; 0.00\n",
      "Train/Val Sim Loss after epoch: 0.0167/0.0177\n",
      "EPOCH 25:\n",
      " Avg. train loss/batch after 10 batches = 0.0154\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 20 batches = 0.0147\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 30 batches = 0.0149\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 40 batches = 0.0164\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 50 batches = 0.0145\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 60 batches = 0.0156\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 70 batches = 0.0154\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 80 batches = 0.0130\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 90 batches = 0.0153\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 100 batches = 0.0191\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 110 batches = 0.0168\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 120 batches = 0.0295\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 130 batches = 0.0163\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 140 batches = 0.0189\n",
      "Last 0.01; 0.00; 0.00\n",
      "Train/Val Sim Loss after epoch: 0.0189/0.0220\n",
      "EPOCH 26:\n",
      " Avg. train loss/batch after 10 batches = 0.0163\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 20 batches = 0.0238\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 30 batches = 0.0181\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 40 batches = 0.0163\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 50 batches = 0.0152\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 60 batches = 0.0151\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 70 batches = 0.0162\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 80 batches = 0.0161\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 90 batches = 0.0156\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 100 batches = 0.0162\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 110 batches = 0.0182\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 120 batches = 0.0165\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 130 batches = 0.0156\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 140 batches = 0.0136\n",
      "Last 0.01; 0.00; 0.00\n",
      "Train/Val Sim Loss after epoch: 0.0136/0.0273\n",
      "EPOCH 27:\n",
      " Avg. train loss/batch after 10 batches = 0.0145\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 20 batches = 0.0139\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 30 batches = 0.0154\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 40 batches = 0.0382\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 50 batches = 0.0237\n",
      "Last 0.02; 0.00; 0.06\n",
      " Avg. train loss/batch after 60 batches = 0.0140\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 70 batches = 0.0186\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 80 batches = 0.0157\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 90 batches = 0.0189\n",
      "Last 0.01; 0.01; 0.00\n",
      " Avg. train loss/batch after 100 batches = 0.0183\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 110 batches = 0.0153\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 120 batches = 0.0136\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 130 batches = 0.0153\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 140 batches = 0.0175\n",
      "Last 0.01; 0.00; 0.00\n",
      "Train/Val Sim Loss after epoch: 0.0175/0.0383\n",
      "EPOCH 28:\n",
      " Avg. train loss/batch after 10 batches = 0.0144\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 20 batches = 0.0164\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 30 batches = 0.0165\n",
      "Last 0.02; 0.00; 0.02\n",
      " Avg. train loss/batch after 40 batches = 0.0158\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 50 batches = 0.0178\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 60 batches = 0.0161\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 70 batches = 0.0167\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 80 batches = 0.0174\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 90 batches = 0.0153\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 100 batches = 0.0123\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 110 batches = 0.0126\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 120 batches = 0.0156\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 130 batches = 0.0211\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 140 batches = 0.0193\n",
      "Last 0.02; 0.00; 0.00\n",
      "Train/Val Sim Loss after epoch: 0.0193/0.0159\n",
      "EPOCH 29:\n",
      " Avg. train loss/batch after 10 batches = 0.0155\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 20 batches = 0.0159\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 30 batches = 0.0146\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 40 batches = 0.0153\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 50 batches = 0.0173\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 60 batches = 0.0156\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 70 batches = 0.0144\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 80 batches = 0.0142\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 90 batches = 0.0180\n",
      "Last 0.02; 0.00; 0.03\n",
      " Avg. train loss/batch after 100 batches = 0.0140\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 110 batches = 0.0147\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 120 batches = 0.0171\n",
      "Last 0.02; 0.00; 0.01\n",
      " Avg. train loss/batch after 130 batches = 0.0248\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 140 batches = 0.0158\n",
      "Last 0.01; 0.00; 0.00\n",
      "Train/Val Sim Loss after epoch: 0.0158/0.1860\n",
      "EPOCH 30:\n",
      " Avg. train loss/batch after 10 batches = 0.0216\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 20 batches = 0.0158\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 30 batches = 0.0156\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 40 batches = 0.0150\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 50 batches = 0.0173\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 60 batches = 0.0195\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 70 batches = 0.0160\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 80 batches = 0.0167\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 90 batches = 0.0197\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 100 batches = 0.0157\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 110 batches = 0.0155\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 120 batches = 0.0159\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 130 batches = 0.0156\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 140 batches = 0.0145\n",
      "Last 0.01; 0.00; 0.00\n",
      "Train/Val Sim Loss after epoch: 0.0145/0.0164\n",
      "EPOCH 31:\n",
      " Avg. train loss/batch after 10 batches = 0.0141\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 20 batches = 0.0165\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 30 batches = 0.0155\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 40 batches = 0.0174\n",
      "Last 0.01; 0.01; 0.02\n",
      " Avg. train loss/batch after 50 batches = 0.0207\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 60 batches = 0.0151\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 70 batches = 0.0146\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 80 batches = 0.0163\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 90 batches = 0.0156\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 100 batches = 0.0143\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 110 batches = 0.0128\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 120 batches = 0.0169\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 130 batches = 0.0178\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 140 batches = 0.0149\n",
      "Last 0.01; 0.00; 0.00\n",
      "Train/Val Sim Loss after epoch: 0.0149/0.0197\n",
      "EPOCH 32:\n",
      " Avg. train loss/batch after 10 batches = 0.0153\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 20 batches = 0.0161\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 30 batches = 0.0198\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 40 batches = 0.0137\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 50 batches = 0.0147\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 60 batches = 0.0163\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 70 batches = 0.0137\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 80 batches = 0.0210\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 90 batches = 0.0141\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 100 batches = 0.0172\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 110 batches = 0.0141\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 120 batches = 0.0465\n",
      "Last 0.02; 0.00; 0.30\n",
      " Avg. train loss/batch after 130 batches = 0.0139\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 140 batches = 0.0165\n",
      "Last 0.02; 0.00; 0.00\n",
      "Train/Val Sim Loss after epoch: 0.0165/0.0163\n",
      "EPOCH 33:\n",
      " Avg. train loss/batch after 10 batches = 0.0223\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 20 batches = 0.0154\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 30 batches = 0.0159\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 40 batches = 0.0142\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 50 batches = 0.0129\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 60 batches = 0.0141\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 70 batches = 0.0163\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 80 batches = 0.0144\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 90 batches = 0.0148\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 100 batches = 0.0133\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 110 batches = 0.0144\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 120 batches = 0.0145\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 130 batches = 0.0117\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 140 batches = 0.0213\n",
      "Last 0.01; 0.00; 0.00\n",
      "Train/Val Sim Loss after epoch: 0.0213/0.0149\n",
      "EPOCH 34:\n",
      " Avg. train loss/batch after 10 batches = 0.0155\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 20 batches = 0.0137\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 30 batches = 0.0242\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 40 batches = 0.0157\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 50 batches = 0.0142\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 60 batches = 0.0149\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 70 batches = 0.0152\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 80 batches = 0.0149\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 90 batches = 0.0144\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 100 batches = 0.0151\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 110 batches = 0.0281\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 120 batches = 0.0132\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 130 batches = 0.0215\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 140 batches = 0.0151\n",
      "Last 0.02; 0.00; 0.00\n",
      "Train/Val Sim Loss after epoch: 0.0151/0.0232\n",
      "EPOCH 35:\n",
      " Avg. train loss/batch after 10 batches = 0.0134\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 20 batches = 0.0147\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 30 batches = 0.0141\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 40 batches = 0.0171\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 50 batches = 0.0140\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 60 batches = 0.0149\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 70 batches = 0.0135\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 80 batches = 0.0134\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 90 batches = 0.0136\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 100 batches = 0.0163\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 110 batches = 0.0135\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 120 batches = 0.0145\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 130 batches = 0.0256\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 140 batches = 0.0164\n",
      "Last 0.02; 0.00; 0.00\n",
      "Train/Val Sim Loss after epoch: 0.0164/0.0154\n",
      "EPOCH 36:\n",
      " Avg. train loss/batch after 10 batches = 0.0169\n",
      "Last 0.01; 0.00; 0.01\n",
      " Avg. train loss/batch after 20 batches = 0.0161\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 30 batches = 0.0145\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 40 batches = 0.0142\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 50 batches = 0.0134\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 60 batches = 0.0160\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 70 batches = 0.0150\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 80 batches = 0.0148\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 90 batches = 0.0167\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 100 batches = 0.0134\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 110 batches = 0.0160\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 120 batches = 0.0187\n",
      "Last 0.02; 0.00; 0.01\n",
      " Avg. train loss/batch after 130 batches = 0.0155\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 140 batches = 0.0144\n",
      "Last 0.01; 0.00; 0.00\n",
      "Train/Val Sim Loss after epoch: 0.0144/0.0295\n",
      "EPOCH 37:\n",
      " Avg. train loss/batch after 10 batches = 0.0137\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 20 batches = 0.0246\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 30 batches = 0.0163\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 40 batches = 0.0149\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 50 batches = 0.0160\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 60 batches = 0.0150\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 70 batches = 0.0153\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 80 batches = 0.0145\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 90 batches = 0.0216\n",
      "Last 0.02; 0.00; 0.06\n",
      " Avg. train loss/batch after 100 batches = 0.0388\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 110 batches = 0.0155\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 120 batches = 0.0159\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 130 batches = 0.0189\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 140 batches = 0.0157\n",
      "Last 0.02; 0.00; 0.00\n",
      "Train/Val Sim Loss after epoch: 0.0157/0.0195\n",
      "EPOCH 38:\n",
      " Avg. train loss/batch after 10 batches = 0.0182\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 20 batches = 0.0154\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 30 batches = 0.0137\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 40 batches = 0.0158\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 50 batches = 0.0178\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 60 batches = 0.0148\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 70 batches = 0.0169\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 80 batches = 0.0162\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 90 batches = 0.0149\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 100 batches = 0.0136\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 110 batches = 0.0151\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 120 batches = 0.0143\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 130 batches = 0.0206\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 140 batches = 0.0156\n",
      "Last 0.01; 0.00; 0.00\n",
      "Train/Val Sim Loss after epoch: 0.0156/0.0165\n",
      "EPOCH 39:\n",
      " Avg. train loss/batch after 10 batches = 0.0130\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 20 batches = 0.0159\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 30 batches = 0.0144\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 40 batches = 0.0171\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 50 batches = 0.0625\n",
      "Last 0.01; 0.00; 0.50\n",
      " Avg. train loss/batch after 60 batches = 0.0168\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 70 batches = 0.0140\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 80 batches = 0.0161\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 90 batches = 0.0140\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 100 batches = 0.0163\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 110 batches = 0.0141\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 120 batches = 0.0140\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 130 batches = 0.0162\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 140 batches = 0.0140\n",
      "Last 0.01; 0.00; 0.00\n",
      "Train/Val Sim Loss after epoch: 0.0140/0.0153\n",
      "EPOCH 40:\n",
      " Avg. train loss/batch after 10 batches = 0.0231\n",
      "Last 0.02; 0.00; 0.08\n",
      " Avg. train loss/batch after 20 batches = 0.0128\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 30 batches = 0.0144\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 40 batches = 0.0142\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 50 batches = 0.0152\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 60 batches = 0.0225\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 70 batches = 0.0151\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 80 batches = 0.0159\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 90 batches = 0.0141\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 100 batches = 0.0171\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 110 batches = 0.0130\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 120 batches = 0.0176\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 130 batches = 0.0143\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 140 batches = 0.0137\n",
      "Last 0.00; 0.00; 0.00\n",
      "Train/Val Sim Loss after epoch: 0.0137/0.0233\n",
      "EPOCH 41:\n",
      " Avg. train loss/batch after 10 batches = 0.0195\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 20 batches = 0.0124\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 30 batches = 0.0146\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 40 batches = 0.0184\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 50 batches = 0.0164\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 60 batches = 0.0145\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 70 batches = 0.0140\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 80 batches = 0.0195\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 90 batches = 0.0162\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 100 batches = 0.0149\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 110 batches = 0.0146\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 120 batches = 0.0138\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 130 batches = 0.0138\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 140 batches = 0.0315\n",
      "Last 0.01; 0.00; 0.00\n",
      "Train/Val Sim Loss after epoch: 0.0315/0.0164\n",
      "EPOCH 42:\n",
      " Avg. train loss/batch after 10 batches = 0.0149\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 20 batches = 0.0340\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 30 batches = 0.0139\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 40 batches = 0.0149\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 50 batches = 0.0139\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 60 batches = 0.0143\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 70 batches = 0.0156\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 80 batches = 0.0137\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 90 batches = 0.0149\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 100 batches = 0.0218\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 110 batches = 0.0150\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 120 batches = 0.0144\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 130 batches = 0.0141\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 140 batches = 0.0154\n",
      "Last 0.01; 0.01; 0.00\n",
      "Train/Val Sim Loss after epoch: 0.0154/0.0126\n",
      "EPOCH 43:\n",
      " Avg. train loss/batch after 10 batches = 0.0135\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 20 batches = 0.0142\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 30 batches = 0.0205\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 40 batches = 0.0154\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 50 batches = 0.0121\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 60 batches = 0.0146\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 70 batches = 0.0135\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 80 batches = 0.0158\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 90 batches = 0.0141\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 100 batches = 0.0133\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 110 batches = 0.0172\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 120 batches = 0.0162\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 130 batches = 0.0131\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 140 batches = 0.0159\n",
      "Last 0.02; 0.00; 0.00\n",
      "Train/Val Sim Loss after epoch: 0.0159/0.0196\n",
      "EPOCH 44:\n",
      " Avg. train loss/batch after 10 batches = 0.0156\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 20 batches = 0.0146\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 30 batches = 0.0125\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 40 batches = 0.0159\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 50 batches = 0.0147\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 60 batches = 0.0143\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 70 batches = 0.0142\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 80 batches = 0.0140\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 90 batches = 0.0143\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 100 batches = 0.0135\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 110 batches = 0.0151\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 120 batches = 0.0153\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 130 batches = 0.0140\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 140 batches = 0.0182\n",
      "Last 0.01; 0.00; 0.00\n",
      "Train/Val Sim Loss after epoch: 0.0182/0.0109\n",
      "EPOCH 45:\n",
      " Avg. train loss/batch after 10 batches = 0.0188\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 20 batches = 0.0210\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 30 batches = 0.0146\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 40 batches = 0.0164\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 50 batches = 0.0195\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 60 batches = 0.0137\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 70 batches = 0.0156\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 80 batches = 0.0150\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 90 batches = 0.0142\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 100 batches = 0.0143\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 110 batches = 0.0155\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 120 batches = 0.0121\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 130 batches = 0.0132\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 140 batches = 0.0144\n",
      "Last 0.01; 0.00; 0.00\n",
      "Train/Val Sim Loss after epoch: 0.0144/0.0190\n",
      "EPOCH 46:\n",
      " Avg. train loss/batch after 10 batches = 0.0168\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 20 batches = 0.0194\n",
      "Last 0.02; 0.00; 0.05\n",
      " Avg. train loss/batch after 30 batches = 0.0216\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 40 batches = 0.0174\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 50 batches = 0.0147\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 60 batches = 0.0150\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 70 batches = 0.0156\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 80 batches = 0.0159\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 90 batches = 0.0162\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 100 batches = 0.0152\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 110 batches = 0.0123\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 120 batches = 0.0148\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 130 batches = 0.0162\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 140 batches = 0.0143\n",
      "Last 0.01; 0.00; 0.00\n",
      "Train/Val Sim Loss after epoch: 0.0143/0.0780\n",
      "EPOCH 47:\n",
      " Avg. train loss/batch after 10 batches = 0.0216\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 20 batches = 0.0160\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 30 batches = 0.0131\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 40 batches = 0.0155\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 50 batches = 0.0136\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 60 batches = 0.0134\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 70 batches = 0.0163\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 80 batches = 0.0146\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 90 batches = 0.0150\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 100 batches = 0.0129\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 110 batches = 0.0171\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 120 batches = 0.0159\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 130 batches = 0.0138\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 140 batches = 0.0160\n",
      "Last 0.02; 0.00; 0.00\n",
      "Train/Val Sim Loss after epoch: 0.0160/0.0108\n",
      "EPOCH 48:\n",
      " Avg. train loss/batch after 10 batches = 0.0138\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 20 batches = 0.0156\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 30 batches = 0.0175\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 40 batches = 0.0247\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 50 batches = 0.0166\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 60 batches = 0.0143\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 70 batches = 0.0149\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 80 batches = 0.0143\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 90 batches = 0.0168\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 100 batches = 0.0134\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 110 batches = 0.0151\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 120 batches = 0.0135\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 130 batches = 0.0141\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 140 batches = 0.0359\n",
      "Last 0.01; 0.00; 0.00\n",
      "Train/Val Sim Loss after epoch: 0.0359/0.0114\n",
      "EPOCH 49:\n",
      " Avg. train loss/batch after 10 batches = 0.0154\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 20 batches = 0.0139\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 30 batches = 0.0259\n",
      "Last 0.02; 0.00; 0.12\n",
      " Avg. train loss/batch after 40 batches = 0.0165\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 50 batches = 0.0150\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 60 batches = 0.0141\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 70 batches = 0.0197\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 80 batches = 0.0145\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 90 batches = 0.0140\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 100 batches = 0.0151\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 110 batches = 0.0154\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 120 batches = 0.0135\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 130 batches = 0.0137\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 140 batches = 0.0155\n",
      "Last 0.01; 0.00; 0.00\n",
      "Train/Val Sim Loss after epoch: 0.0155/0.0101\n",
      "EPOCH 50:\n",
      " Avg. train loss/batch after 10 batches = 0.0221\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 20 batches = 0.0148\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 30 batches = 0.0157\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 40 batches = 0.0148\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 50 batches = 0.0250\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 60 batches = 0.0133\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 70 batches = 0.0124\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 80 batches = 0.0224\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 90 batches = 0.0148\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 100 batches = 0.0138\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 110 batches = 0.0141\n",
      "Last 0.02; 0.00; 0.00\n",
      " Avg. train loss/batch after 120 batches = 0.0133\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 130 batches = 0.0141\n",
      "Last 0.01; 0.00; 0.00\n",
      " Avg. train loss/batch after 140 batches = 0.0140\n",
      "Last 0.02; 0.00; 0.00\n",
      "Train/Val Sim Loss after epoch: 0.0140/0.1307\n",
      "CPU times: user 5min 11s, sys: 24.8 s, total: 5min 36s\n",
      "Wall time: 5min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# training the neural network for many epochs\n",
    "\n",
    "epoch_number = 0\n",
    "EPOCHS = 50\n",
    "\n",
    "sim_val_loss = []\n",
    "sim_train_loss = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "    wt_repr, wt_cov, wt_std = (1, 1, 1)\n",
    "\n",
    "    # Gradient tracking\n",
    "    similarity_embedding.train(True)\n",
    "    avg_train_loss = train_one_epoch_se(epoch_number, writer, train_data_loader_paper, similarity_embedding,\n",
    "                                        optimizer, vicreg_loss, wt_repr=wt_repr, wt_cov=wt_cov, wt_std=wt_std)\n",
    "    sim_train_loss.append(avg_train_loss)\n",
    "    \n",
    "    # no gradient tracking, for validation\n",
    "    similarity_embedding.train(False)\n",
    "    similarity_embedding.eval()\n",
    "    avg_val_loss = val_one_epoch_se(epoch_number, writer, val_data_loader_paper, similarity_embedding,\n",
    "                                    vicreg_loss, wt_repr=wt_repr, wt_cov=wt_cov, wt_std=wt_std)\n",
    "    sim_val_loss.append(avg_val_loss)\n",
    "    \n",
    "    print(f\"Train/Val Sim Loss after epoch: {avg_train_loss:.4f}/{avg_val_loss:.4f}\")\n",
    "\n",
    "    epoch_number += 1\n",
    "    scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0ccfbdf-2e7b-4430-b13d-8c9bb2374976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the train/val loss \n",
    "\n",
    "epoch_list = range(0,len(sim_train_loss))\n",
    "plt.plot(epoch_list, sim_train_loss, label = 'Similarity Embedding (Train)', color = 'royalblue', alpha = 0.8, marker = 's')\n",
    "plt.plot(epoch_list, sim_val_loss, label = 'Similarity Embedding (Val)', color = 'lightsteelblue', alpha=0.8, linestyle=\"dashed\")\n",
    "plt.legend()\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Loss')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
